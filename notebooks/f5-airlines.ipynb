{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#from  pandasgui import show\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.calibration import cross_val_predict\n",
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 103904 entries, 0 to 103903\n",
      "Data columns (total 23 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   Gender                             103904 non-null  object \n",
      " 1   Customer Type                      103904 non-null  object \n",
      " 2   Age                                103904 non-null  int64  \n",
      " 3   Type of Travel                     103904 non-null  object \n",
      " 4   Class                              103904 non-null  object \n",
      " 5   Flight Distance                    103904 non-null  int64  \n",
      " 6   Inflight wifi service              103904 non-null  int64  \n",
      " 7   Departure/Arrival time convenient  103904 non-null  int64  \n",
      " 8   Ease of Online booking             103904 non-null  int64  \n",
      " 9   Gate location                      103904 non-null  int64  \n",
      " 10  Food and drink                     103904 non-null  int64  \n",
      " 11  Online boarding                    103904 non-null  int64  \n",
      " 12  Seat comfort                       103904 non-null  int64  \n",
      " 13  Inflight entertainment             103904 non-null  int64  \n",
      " 14  On-board service                   103904 non-null  int64  \n",
      " 15  Leg room service                   103904 non-null  int64  \n",
      " 16  Baggage handling                   103904 non-null  int64  \n",
      " 17  Checkin service                    103904 non-null  int64  \n",
      " 18  Inflight service                   103904 non-null  int64  \n",
      " 19  Cleanliness                        103904 non-null  int64  \n",
      " 20  Departure Delay in Minutes         103904 non-null  int64  \n",
      " 21  Arrival Delay in Minutes           103594 non-null  float64\n",
      " 22  satisfaction                       103904 non-null  object \n",
      "dtypes: float64(1), int64(17), object(5)\n",
      "memory usage: 18.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "train_data = pd.read_csv(\"../airline_passenger_satisfaction.csv\")\n",
    "# primeros_100_registros = train_data.iloc[:100]\n",
    "# test_data = pd.DataFrame(primeros_100_registros)\n",
    "#primer_registro = train_data.iloc[0]\n",
    "#test_data = pd.DataFrame([primer_registro])\n",
    "train_data.drop([\"Unnamed: 0\" ,\"id\"] , axis = 1 ,inplace = True)\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtenemos un arreglo con los nombres de las variables segun su tipo\n",
    "imputer_cols = [cname for cname in train_data.columns if train_data[cname].dtype in ['int64', 'float64']]\n",
    "categorical_cols = [cname for cname in train_data.columns if train_data[cname].dtype == \"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean' )\n",
    "imputer.fit(train_data[imputer_cols])\n",
    "train_data[imputer_cols] = imputer.transform(train_data[imputer_cols])\n",
    "#test_data[imputer_cols] = imputer.transform(test_data[imputer_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# completamos valores nulos  en las columnas categoricas con la moda\n",
    "def fill_null_with_mode(column, train_df):#test_df\n",
    "    moda = train_df[column].mode().iloc[0]\n",
    "    train_df[column] = train_df[column].fillna(moda)\n",
    "    #test_df[column] = test_df[column].fillna(moda)\n",
    "\n",
    "# Aplicar la función de llenado de valores nulos\n",
    "fill_null_with_mode(categorical_cols, train_data)#test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Customer Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Type of Travel</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight Distance</th>\n",
       "      <th>Inflight wifi service</th>\n",
       "      <th>Departure/Arrival time convenient</th>\n",
       "      <th>Ease of Online booking</th>\n",
       "      <th>Gate location</th>\n",
       "      <th>Food and drink</th>\n",
       "      <th>Online boarding</th>\n",
       "      <th>Seat comfort</th>\n",
       "      <th>Inflight entertainment</th>\n",
       "      <th>On-board service</th>\n",
       "      <th>Leg room service</th>\n",
       "      <th>Baggage handling</th>\n",
       "      <th>Checkin service</th>\n",
       "      <th>Inflight service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Departure Delay in Minutes</th>\n",
       "      <th>Arrival Delay in Minutes</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco Plus</td>\n",
       "      <td>460.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>235.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>562.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>214.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103899</th>\n",
       "      <td>Female</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>192.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103900</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>2347.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103901</th>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103902</th>\n",
       "      <td>Female</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Eco</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103903</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral or dissatisfied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103904 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Gender      Customer Type   Age   Type of Travel     Class  \\\n",
       "0         Male     Loyal Customer  13.0  Personal Travel  Eco Plus   \n",
       "1         Male  disloyal Customer  25.0  Business travel  Business   \n",
       "2       Female     Loyal Customer  26.0  Business travel  Business   \n",
       "3       Female     Loyal Customer  25.0  Business travel  Business   \n",
       "4         Male     Loyal Customer  61.0  Business travel  Business   \n",
       "...        ...                ...   ...              ...       ...   \n",
       "103899  Female  disloyal Customer  23.0  Business travel       Eco   \n",
       "103900    Male     Loyal Customer  49.0  Business travel  Business   \n",
       "103901    Male  disloyal Customer  30.0  Business travel  Business   \n",
       "103902  Female  disloyal Customer  22.0  Business travel       Eco   \n",
       "103903    Male     Loyal Customer  27.0  Business travel  Business   \n",
       "\n",
       "        Flight Distance  Inflight wifi service  \\\n",
       "0                 460.0                    3.0   \n",
       "1                 235.0                    3.0   \n",
       "2                1142.0                    2.0   \n",
       "3                 562.0                    2.0   \n",
       "4                 214.0                    3.0   \n",
       "...                 ...                    ...   \n",
       "103899            192.0                    2.0   \n",
       "103900           2347.0                    4.0   \n",
       "103901           1995.0                    1.0   \n",
       "103902           1000.0                    1.0   \n",
       "103903           1723.0                    1.0   \n",
       "\n",
       "        Departure/Arrival time convenient  Ease of Online booking  \\\n",
       "0                                     4.0                     3.0   \n",
       "1                                     2.0                     3.0   \n",
       "2                                     2.0                     2.0   \n",
       "3                                     5.0                     5.0   \n",
       "4                                     3.0                     3.0   \n",
       "...                                   ...                     ...   \n",
       "103899                                1.0                     2.0   \n",
       "103900                                4.0                     4.0   \n",
       "103901                                1.0                     1.0   \n",
       "103902                                1.0                     1.0   \n",
       "103903                                3.0                     3.0   \n",
       "\n",
       "        Gate location  Food and drink  Online boarding  Seat comfort  \\\n",
       "0                 1.0             5.0              3.0           5.0   \n",
       "1                 3.0             1.0              3.0           1.0   \n",
       "2                 2.0             5.0              5.0           5.0   \n",
       "3                 5.0             2.0              2.0           2.0   \n",
       "4                 3.0             4.0              5.0           5.0   \n",
       "...               ...             ...              ...           ...   \n",
       "103899            3.0             2.0              2.0           2.0   \n",
       "103900            4.0             2.0              4.0           5.0   \n",
       "103901            3.0             4.0              1.0           5.0   \n",
       "103902            5.0             1.0              1.0           1.0   \n",
       "103903            3.0             1.0              1.0           1.0   \n",
       "\n",
       "        Inflight entertainment  On-board service  Leg room service  \\\n",
       "0                          5.0               4.0               3.0   \n",
       "1                          1.0               1.0               5.0   \n",
       "2                          5.0               4.0               3.0   \n",
       "3                          2.0               2.0               5.0   \n",
       "4                          3.0               3.0               4.0   \n",
       "...                        ...               ...               ...   \n",
       "103899                     2.0               3.0               1.0   \n",
       "103900                     5.0               5.0               5.0   \n",
       "103901                     4.0               3.0               2.0   \n",
       "103902                     1.0               4.0               5.0   \n",
       "103903                     1.0               1.0               1.0   \n",
       "\n",
       "        Baggage handling  Checkin service  Inflight service  Cleanliness  \\\n",
       "0                    4.0              4.0               5.0          5.0   \n",
       "1                    3.0              1.0               4.0          1.0   \n",
       "2                    4.0              4.0               4.0          5.0   \n",
       "3                    3.0              1.0               4.0          2.0   \n",
       "4                    4.0              3.0               3.0          3.0   \n",
       "...                  ...              ...               ...          ...   \n",
       "103899               4.0              2.0               3.0          2.0   \n",
       "103900               5.0              5.0               5.0          4.0   \n",
       "103901               4.0              5.0               5.0          4.0   \n",
       "103902               1.0              5.0               4.0          1.0   \n",
       "103903               4.0              4.0               3.0          1.0   \n",
       "\n",
       "        Departure Delay in Minutes  Arrival Delay in Minutes  \\\n",
       "0                             25.0                      18.0   \n",
       "1                              1.0                       6.0   \n",
       "2                              0.0                       0.0   \n",
       "3                             11.0                       9.0   \n",
       "4                              0.0                       0.0   \n",
       "...                            ...                       ...   \n",
       "103899                         3.0                       0.0   \n",
       "103900                         0.0                       0.0   \n",
       "103901                         7.0                      14.0   \n",
       "103902                         0.0                       0.0   \n",
       "103903                         0.0                       0.0   \n",
       "\n",
       "                   satisfaction  \n",
       "0       neutral or dissatisfied  \n",
       "1       neutral or dissatisfied  \n",
       "2                     satisfied  \n",
       "3       neutral or dissatisfied  \n",
       "4                     satisfied  \n",
       "...                         ...  \n",
       "103899  neutral or dissatisfied  \n",
       "103900                satisfied  \n",
       "103901  neutral or dissatisfied  \n",
       "103902  neutral or dissatisfied  \n",
       "103903  neutral or dissatisfied  \n",
       "\n",
       "[103904 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preparamos los datos para dividirlos\n",
    "#train_data.drop([\"Unnamed: 0\" ,\"id\"] , axis = 1 ,inplace = True)\n",
    "#test_data.drop([\"Unnamed: 0\" ,\"id\",\"satisfaction\"] , axis = 1 ,inplace = True)\n",
    "# TODO no estoy seguro si debo elimiar satisfaction de test\n",
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una copia de los datos originales para evitar modificarlos\n",
    "X = train_data.drop(\"satisfaction\", axis=1)\n",
    "y = train_data[\"satisfaction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         neutral or dissatisfied\n",
       "1         neutral or dissatisfied\n",
       "2                       satisfied\n",
       "3         neutral or dissatisfied\n",
       "4                       satisfied\n",
       "                   ...           \n",
       "103899    neutral or dissatisfied\n",
       "103900                  satisfied\n",
       "103901    neutral or dissatisfied\n",
       "103902    neutral or dissatisfied\n",
       "103903    neutral or dissatisfied\n",
       "Name: satisfaction, Length: 103904, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape (X): (103904, 24)\n",
      "Training set shape (y): (103904,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Lista de columnas numéricas\n",
    "numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Lista de columnas categóricas en X\n",
    "categorical_cols = [cname for cname in X.columns if X[cname].dtype == \"object\"]\n",
    "\n",
    "# Escalar las características numéricas\n",
    "numerical_transformer = Pipeline(steps=[('scaler', MinMaxScaler())])\n",
    "\n",
    "# Codificar one-hot las características categóricas\n",
    "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(drop='if_binary', handle_unknown='ignore', sparse=False))])\n",
    "\n",
    "# Combinar transformaciones para X\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "\n",
    "# Mapear 'satisfied' a 1 y 'neutral' a 0\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Aplicar las transformaciones a X\n",
    "X = preprocessor.fit_transform(X)\n",
    "\n",
    "# Imprimir nueva forma de X\n",
    "print('Training set shape (X):', X.shape)\n",
    "\n",
    "# Imprimir nueva forma de y\n",
    "print('Training set shape (y):', y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.8,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': range(20, 101, 20),\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion' : ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "list(param_grid['n_estimators'])\n",
    "\n",
    "scoring = 'accuracy'\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=scoring, cv=2, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 90 candidates, totalling 180 fits\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=20; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=20; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=40; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=40; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=60; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=60; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=80; total time=   3.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=80; total time=   3.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=100; total time=   4.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2, n_estimators=100; total time=   4.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=20; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=20; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=40; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=40; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=60; total time=   2.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=60; total time=   2.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=80; total time=   3.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=80; total time=   3.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=100; total time=   4.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=5, n_estimators=100; total time=   4.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=20; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=40; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=40; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=60; total time=   2.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=60; total time=   2.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=80; total time=   3.2s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=80; total time=   3.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=100; total time=   4.0s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=10, n_estimators=100; total time=   4.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=60; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=60; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=80; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=80; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=2, n_estimators=100; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=40; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=60; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=60; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=80; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=80; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=100; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=5, n_estimators=100; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=40; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=60; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=60; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=80; total time=   1.5s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=80; total time=   1.4s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=5, min_samples_split=10, n_estimators=100; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=20; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=40; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=40; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=60; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=60; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=80; total time=   2.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=80; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=100; total time=   3.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=2, n_estimators=100; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=20; total time=   0.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=40; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=40; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=60; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=60; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=80; total time=   2.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=80; total time=   2.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=100; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=5, n_estimators=100; total time=   3.1s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=40; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=40; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=60; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=60; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=80; total time=   2.4s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=80; total time=   2.5s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=100; total time=   3.2s\n",
      "[CV] END criterion=gini, max_depth=10, min_samples_split=10, n_estimators=100; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=20; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=20; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=40; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=40; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=60; total time=   2.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=60; total time=   2.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=80; total time=   3.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=80; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=100; total time=   4.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2, n_estimators=100; total time=   4.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=20; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=20; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=40; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=40; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=60; total time=   2.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=60; total time=   2.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=80; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=80; total time=   3.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=100; total time=   4.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=5, n_estimators=100; total time=   4.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=20; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=20; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=40; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=40; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=60; total time=   2.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=60; total time=   2.6s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=80; total time=   3.4s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=80; total time=   3.7s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=100; total time=   4.2s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=10, n_estimators=100; total time=   4.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=20; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=40; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=40; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=60; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=60; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=80; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=80; total time=   1.6s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=100; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=2, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=20; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=40; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=40; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=60; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=60; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=80; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=80; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=100; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=5, n_estimators=100; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=20; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=40; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=40; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=60; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=60; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=80; total time=   1.7s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=80; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=100; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=5, min_samples_split=10, n_estimators=100; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=20; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=40; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=40; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=60; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=60; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=80; total time=   2.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=80; total time=   2.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=100; total time=   3.3s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=2, n_estimators=100; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=20; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=40; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=40; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=60; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=60; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=80; total time=   2.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=80; total time=   2.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=100; total time=   3.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=5, n_estimators=100; total time=   3.2s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=20; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=20; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=40; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=40; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=60; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=60; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=80; total time=   2.6s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=80; total time=   2.9s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=100; total time=   3.7s\n",
      "[CV] END criterion=entropy, max_depth=10, min_samples_split=10, n_estimators=100; total time=   3.1s\n",
      "Best hyperparameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'n_estimators': 80}\n",
      "Best score: 0.9580260599346813\n",
      "Testing accuracy: 0.961503296280256\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    " \n",
    "# Print the best hyperparameters and the best score\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n",
    " \n",
    "# Re-train the model with the best hyperparameters\n",
    "best_clf = grid_search.best_estimator_\n",
    "best_clf.fit(X_train, y_train)\n",
    " \n",
    "# Test the model with the best hyperparameters on the testing data\n",
    "accuracy = best_clf.score(X_test, y_test)\n",
    "print(\"Testing accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.960756950543171\n",
      "Confusion Matrix:\n",
      " [[46144  1022]\n",
      " [ 2240 33717]]\n",
      "Recall: 0.9377033679116723\n",
      "F1 Score: 0.9538587756025801\n"
     ]
    }
   ],
   "source": [
    "# Crear el pipeline con los parametros del grid search\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('model', RandomForestClassifier(criterion = 'gini', max_depth = None, min_samples_split = 2, n_estimators = 80))\n",
    "])\n",
    "\n",
    "# Realizar la validación cruzada y obtener las probabilidades y los scores\n",
    "predicted = cross_val_predict(my_pipeline, X_train, y_train, cv=5)\n",
    "\n",
    "accuracy_scores = accuracy_score(y_train, predicted)\n",
    "confusion = confusion_matrix(y_train, predicted)\n",
    "recall = recall_score(y_train, predicted)\n",
    "f1 = f1_score(y_train, predicted)\n",
    "\n",
    "# Imprime las métricas para cada pliegue\n",
    "print(\"Accuracy:\", accuracy_scores)\n",
    "print(\"Confusion Matrix:\\n\", confusion)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(criterion = 'gini', max_depth= None, min_samples_split=2, n_estimators=100)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier.predict(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [103904, 20781]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ferna\\Desktop\\Git(Hub)\\F5-Factoria\\F5-Airlines\\notebooks\\f5-airlines.ipynb Cell 17\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ferna/Desktop/Git%28Hub%29/F5-Factoria/F5-Airlines/notebooks/f5-airlines.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Calcular promedio de las probabilidades de la clase positiva\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ferna/Desktop/Git%28Hub%29/F5-Factoria/F5-Airlines/notebooks/f5-airlines.ipynb#X20sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#preds = proba_predictions[:, 1].mean()\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ferna/Desktop/Git%28Hub%29/F5-Factoria/F5-Airlines/notebooks/f5-airlines.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ferna/Desktop/Git%28Hub%29/F5-Factoria/F5-Airlines/notebooks/f5-airlines.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Calcular promedio del score de precisión\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ferna/Desktop/Git%28Hub%29/F5-Factoria/F5-Airlines/notebooks/f5-airlines.ipynb#X20sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m average_accuracy \u001b[39m=\u001b[39m accuracy_score(y, y_pred)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ferna/Desktop/Git%28Hub%29/F5-Factoria/F5-Airlines/notebooks/f5-airlines.ipynb#X20sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#Matriz\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ferna/Desktop/Git%28Hub%29/F5-Factoria/F5-Airlines/notebooks/f5-airlines.ipynb#X20sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m conf_matrix \u001b[39m=\u001b[39m confusion_matrix(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\ferna\\miniconda3\\envs\\SpaceshipTitanic\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:192\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m validate_parameter_constraints(\n\u001b[0;32m    188\u001b[0m     parameter_constraints, params, caller_name\u001b[39m=\u001b[39mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[0;32m    189\u001b[0m )\n\u001b[0;32m    191\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    193\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    199\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    201\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    202\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\ferna\\miniconda3\\envs\\SpaceshipTitanic\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:221\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[39mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[39m0.5\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[39m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    222\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    223\u001b[0m \u001b[39mif\u001b[39;00m y_type\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39mmultilabel\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\ferna\\miniconda3\\envs\\SpaceshipTitanic\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     60\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[0;32m     62\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m     87\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     88\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ferna\\miniconda3\\envs\\SpaceshipTitanic\\Lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [103904, 20781]"
     ]
    }
   ],
   "source": [
    "# Calcular promedio de las probabilidades de la clase positiva\n",
    "#preds = proba_predictions[:, 1].mean()\n",
    "\n",
    "# Calcular promedio del score de precisión\n",
    "average_accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "#Matriz\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Calcula la precisión\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Calcula el recall\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Calcula el F1-Score\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "# Imprimir los resultados\n",
    "#print(\"Average probability:\", preds)\n",
    "print(\"Average accuracy:\", average_accuracy)\n",
    "print(\"Matriz de Confusión:\\n\", conf_matrix)\n",
    "print(f\"Precisión: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average probability**  \n",
    "Esto nos indica que de la cantidad de clientes satisfechos (satisfied) hay un 43.35% del total general , por lo tanto lo restante serian los que estan como \"neutral or dissatisfied\".\n",
    "\n",
    "**Average accuracy**  \n",
    "Aqui podemos observar que en cuanto a predicciones correctas, es decir que nuestro modelo cuenta con un 96.15% de acertividad en cuanto a las pruebas realizadas.\n",
    "\n",
    "**Matriz de confusión**  \n",
    "La matriz de confusión es la variable que nos permite determinar la capacidad del modelo para evitar clasificar incorrectamente las instancias negativas como positivas. A diferencia de la precisión uqe nos da una vision general de la acertividad , la matriz de confusión se utiliza para saber la categorizacion de las predicciones.\n",
    "\n",
    "En esta métrica nos indica cuantos verdaderos positivos hay (11510) es decir que la mayoria de resultados aqui estan estado \"satisfied\"; Falsos positivos aqui se puede ver que el modelo interpretó 266 clientes que en realidad estan en estado  \"neutral or dissatisfied\" pero que el modelo tomó como \"satisfied\"; En cuanto a 579 , nos indica que el modelo interpreta estos datos como falsos negativos , que quiere decir que en realidad estos clientes estan como \"satisfied\" pero el modelo los tomó como \"neutral or dissatisfied\"; por último 8426 que significa que aqui estan los verdaderos negativos , que aqui todos los clientes estan como \"neutral or dissatisfied\".\n",
    "\n",
    "**Precisión**  \n",
    "Esto nos indica que de toda la base de datos el 96% es acertado con respecto a predicciones positivas, a diferencia de ka atriz de confusión , la precisión no tiene en cuenta estos falsos positivos y se centra en la proporción de predicciones positivas correctas en relación con todas las predicciones positivas. \n",
    "\n",
    "**Recall**  \n",
    "El recall responde a la pregunta: \"De todos los casos positivos reales, ¿cuántos de ellos el modelo fue capaz de identificar correctamente?\". Es una métrica importante en problemas donde la detección de todos los casos positivos es crítica, como en la detección temprana de enfermedades o la identificación de fraudes. En este caso se puede determinar que el 96% de de los casos verdaderos positivos es correctamente identificado por el modelo.\n",
    "\n",
    "**F1-Score**  \n",
    "El F1-Score es útil cuando deseamos tener un equilibrio entre la precisión y el recall. Proporciona una puntuación que combina ambas métricas y es útil cuando ninguna de las dos métricas por sí sola es suficiente. En nuestro caso indica que está cerca al 1.0 entonces indica un buen equilibrio entre la precisión y el recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtiene la importancia de las características\n",
    "importancia_caracteristicas = classifier.feature_importances_\n",
    "\n",
    "# Puedes imprimir la importancia de cada característica\n",
    "for i, importancia in enumerate(importancia_caracteristicas):\n",
    "    print(f'Característica {i}: {importancia}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapea las etiquetas a valores binarios\n",
    "y_true_binary = [1 if label == \"satisfied\" else 0 for label in y_test]\n",
    "\n",
    "# Obtén las probabilidades de predicción del modelo (por ejemplo, un clasificador de bosque aleatorio)\n",
    "probs = classifier.predict_proba(X_test)  # X_test son las características de prueba\n",
    "\n",
    "# Calcula la curva ROC especificando pos_label=1\n",
    "fpr, tpr, umbrales = roc_curve(y_true_binary, probs[:, 1], pos_label=1)\n",
    "\n",
    "# Calcula el área bajo la curva ROC (AUC-ROC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Grafica la curva ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisis de curva ROC \n",
    "\n",
    "En la curva de ROC podremos notar como el modelo tiene un 0.99 de acertividad a la hora de clasificar, sabiendo distinguir correctamente entre valores correctos e incorrectos con respecto al humbral. La curva de satisfechos y la curva de no satisfechos no se superponen casi en lo absoluto, permitiendo al modelo una facil identificacion y teniendo un minimo error al distinguir entre uno o el otro. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "F5-Airlines-CuSJDrj7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
